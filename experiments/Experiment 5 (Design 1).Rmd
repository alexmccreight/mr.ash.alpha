---
title: "Experiment 5 (Design 1)"
author: "Youngseok Kim"
date: "4/24/2019"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This .Rmd file is to reproduce the result for a figure in the paper. Results for timings can be slightly different even in the same computing machine. Also, it can be nontrivially different if you use different computing machine. But it should not be very different. Anyway, the prediction error presented below must be the same.

### Load libraries, packages and codes

We load libraries, packages and codes for the simulation and for the plotting.

```{r}
library(Matrix); library(Rcpp); library(varbvs); library(ggplot2); library(cowplot);
library(glmnet); library(susieR); library(BGLR); library(varbvs2); library(L0Learn)
```

###

### Simulation setting

## Simulation

### Scenario 1

```{r}
pred1 = matrix(0,20,10)
t1    = matrix(0,20,10)
for (i in 1:20) {
  seed              = 2010 + i
  set.seed(seed)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  data$X           <- rnorm(dim(data$X)[1]) * sqrt(0.5) + data$X * sqrt(0.5)
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  
  standardize       = FALSE
  
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.05,0.95)) == 1)
  beta[nzind]       = rnorm(length(nzind))
  y.total           = data$X %*% beta + 5 * rnorm(n.total)
  
  y                 = y.total[train.index]
  y.test            = y.total[test.index]
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((data$X %*% beta)^2) / mean(y.total^2),"\n")

  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred1[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "mrash2"     = norm(y.test - predict(fit.mrash2, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t1[i,] =     c("mrash"      = t.mrash[3],
                 "mrash2"     = t.mrash2[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred1[i,],"\n")
  cat(t1[i,],"\n")
}
```

```{r}
pred3 = matrix(0,20,10)
t3    = matrix(0,20,10)
for (i in 1:20) {
  seed              = 2010 + i
  set.seed(seed)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  data$X           <- rnorm(dim(data$X)[1]) * sqrt(0.5) + data$X * sqrt(0.5)
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  
  standardize       = FALSE
  
  set.seed(seed)
  beta              = double(p)
  beta[sample(p,1)] = 5
  y.total           = data$X %*% beta + rnorm(n.total)
  
  y                 = y.total[train.index]
  y.test            = y.total[test.index]
  sa2               = (sqrt(1.5)^(0:19) - 1)^2

  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, L = length(nzind), standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  path.order        = lasso_order(fit.lasso$glmnet.fit)
  univar.order      = order(abs(t(X) %*% y), decreasing = TRUE)
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2, method = "update_g",
                               stepsize = 1, max.iter = 2000, standardize = standardize,
                               tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash2          = system.time(
  fit.mrash2       <- mr_ash(X = X, y = y, sa2 = sa2, method = "update_g",
                               stepsize = 1, max.iter = 2000, beta.init = fit.lasso$beta, standardize = standardize,
                               tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred3[i,] =  c("mrash"      = norm(y.test - predict.mrash(fit.mrash, X.test), '2'),
                 "mrash2"      = norm(y.test - predict.mrash(fit.mrash2, X.test), '2'),
                 "susie"      = norm(y.test - predict.susie(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict.glmnet(fit.lasso$glmnet.fit, newx = X.test,
                                                                 s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict.glmnet(fit.ridge$glmnet.fit, newx = X.test,
                                                                 s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict.glmnet(fit.enet$glmnet.fit, newx = X.test,
                                                                 s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t3[i,] =     c("mrash"      = t.mrash[3],
                 "mrash2"      = t.mrash2[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred3[i,],"\n")
  cat(t3[i,],"\n")
}
```

```{r}
pred5 = matrix(0,20,10)
t5    = matrix(0,20,10)
for (i in 1:20) {
  seed              = 2010 + i
  set.seed(seed)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  data$X           <- rnorm(dim(data$X)[1]) * sqrt(0.5) + data$X * sqrt(0.5)
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  
  standardize       = FALSE
  
  beta              = generate_beta(p = p, pi0 = 0.5, signal.shape = "polygenic", signal.strength = 1, seed = seed)
  y.total           = data$X %*% beta + rnorm(n.total)
  
  y                 = y.total[train.index]
  y.test            = y.total[test.index]
  sa2               = (sqrt(1.5)^(0:19) - 1)^2

  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, L = length(nzind), standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  path.order        = lasso_order(fit.lasso$glmnet.fit)
  univar.order      = order(abs(t(X) %*% y), decreasing = TRUE)
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2, method = "update_g",
                               stepsize = 1, max.iter = 2000, standardize = standardize,
                               tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash2          = system.time(
  fit.mrash2       <- mr_ash(X = X, y = y, sa2 = sa2, method = "update_g",
                               stepsize = 1, max.iter = 2000, beta.init = fit.lasso$beta, standardize = standardize,
                               tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred5[i,] =  c("mrash"      = norm(y.test - predict.mrash(fit.mrash, X.test), '2'),
                 "mrash2"      = norm(y.test - predict.mrash(fit.mrash2, X.test), '2'),
                 "susie"      = norm(y.test - predict.susie(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict.glmnet(fit.lasso$glmnet.fit, newx = X.test,
                                                                 s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict.glmnet(fit.ridge$glmnet.fit, newx = X.test,
                                                                 s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict.glmnet(fit.enet$glmnet.fit, newx = X.test,
                                                                 s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t5[i,] =     c("mrash"      = t.mrash[3],
                 "mrash2"      = t.mrash2[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred5[i,],"\n")
  cat(t5[i,],"\n")
}
```

## Save results

We save results as follows. One may find .txt files in the following path.

```{r}
df.pred1 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 20),
                      "pred" = c(pred1))
df.pred3 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 10),
                      "pred" = c(pred3))
df.pred5 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 10),
                      "pred" = c(pred5))
df.time1 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 20),
                      "time" = c(t1))
df.time3 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 10),
                      "time" = c(t3))
df.time5 = data.frame("fit" = rep(c("mrash","mrash2","SUSIE","VARBVS","L0Learn","LASSO",
                                    "RIDGE","E-NET","BLASSO","BayesB"), each = 10),
                      "pred" = c(t5))
write.table(df.pred1, "~/git/mrashr/output/Scenario1_pred1.txt", sep = ",")
```
---
title: "Experiments 8 (Design 4)"
author: "Youngseok Kim"
date: "4/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This .Rmd file is to reproduce the result for a figure in the paper. Results for timings can be slightly different even in the same computing machine. Also, it can be nontrivially different if you use different computing machine. But it should not be very different. Anyway, the prediction error presented below must be the same.

### Load libraries, packages and codes

We load libraries, packages and codes for the simulation and for the plotting.

```{r}
library(Matrix); library(Rcpp); library(varbvs); library(ggplot2); library(cowplot);
library(glmnet); library(susieR); library(BGLR); library(L0Learn); library(varbvs2)
```

### Simulation setting

#### Design matrix

We will use is an independent low dimensional Gaussian ensemble design. For abbreviation, we will call this design matrix "IndepLowdimGauss". A matrix size $n = 1010$ and $p = 1000$ will be fixed. The design matrix will be generated as follows.

```{r}
standardize = FALSE
#X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
```

Note that the design matrix $X$ is not centered, and not standardized. 

#### Signal shapes

#### Proportion of variance explained



## Simulation

### Signal Shape 1 : SparseNormal

#### Signal = SparseNormal, PVE = 0.9

```{r}
pred11 = matrix(0,20,9)
t11    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.1,0.9)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(400/9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred11[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t11[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred11[i,],"\n")
  cat(t11[i,],"\n")
}
```

#### Signal = SparseNormal, PVE = 0.5

```{r}
pred12 = matrix(0,20,9)
t12    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.1,0.9)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(400)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred12[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t12[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred12[i,],"\n")
  cat(t12[i,],"\n")
}
```

#### Signal = SparseNormal, PVE = 0.1

```{r}
pred13 = matrix(0,20,9)
t13    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.01,0.99)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(sum(beta^2) * 9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred13[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t13[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred13[i,],"\n")
  cat(t13[i,],"\n")
}
```

### Signal shape 2

#### Signal = SparseConstant, PVE = 0.9

```{r, results='hide'}
pred21 = matrix(0,20,9)
t21    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  beta[sample(p,50,replace = FALSE)]      <- 2
  sigma             = sqrt(200/9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred21[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t21[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred21[i,],"\n")
  cat(t21[i,],"\n")
}
```

### Signal = SparseConstant, PVE = 0.5

```{r}
pred22 = matrix(0,20,9)
t22    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  beta[sample(p,50,replace = FALSE)]      <- 2
  sigma             = sqrt(200)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred22[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t22[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred22[i,],"\n")
  cat(t22[i,],"\n")
}
```

#### Signal = SparseConstant, PVE = 0.1

```{r}
pred23 = matrix(0,20,9)
t23    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  beta[sample(p,50,replace = FALSE)]      <- 2
  sigma             = sqrt(200 * 9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred23[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t23[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred23[i,],"\n")
  cat(t23[i,],"\n")
}
```

### Signal shape 3

#### Signal = ThreePointMass, PVE = 0.9

```{r, message = FALSE}
pred31 = matrix(0,20,9)
t31    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  ind              <- sample(p,200,replace = FALSE)
  beta[ind[1:10]]       <- 5
  beta[ind[11:100]]     <- 1
  sigma             = sqrt(sum(beta^2)/9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred31[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t31[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred31[i,],"\n")
  cat(t31[i,],"\n")
}
```

### Signal = ThreePointMass, PVE = 0.5

```{r}
pred32 = matrix(0,20,9)
t32    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  ind              <- sample(p,200,replace = FALSE)
  beta[ind[1:10]]       <- 5
  beta[ind[11:100]]     <- 1
  sigma             = sqrt(sum(beta^2))
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred32[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t32[i,] =     c("mrash"      = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred32[i,],"\n")
  cat(t32[i,],"\n")
}
```

#### Signal = TwoPointMass, PVE = 0.1

```{r}
pred33 = matrix(0,20,9)
t33    = matrix(0,20,9)
for (i in 1:20) {
  set.seed(2010 + i)
  X                <- matrix(rnorm(1010 * 1000), 1010, 1000)
  p                 = 1000
  beta             <- rep(0, 1000)
  ind              <- sample(p,200,replace = FALSE)
  beta[ind[1:10]]       <- 5
  beta[ind[11:100]]     <- 1
  sigma             = sqrt(sum(beta^2)*9)
  y                <- X %*% beta + sigma * rnorm(1010)
  X.test           <- matrix(rnorm(1010 * 1000), 1010, 1000)
  y.test           <- X.test %*% beta + sigma * rnorm(1010)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.susie           = system.time(
  fit.susie        <- susie(X = X, Y = y, standardize = standardize))
  fit.susie$beta    = coef(fit.susie)[-1]
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, standardize = standardize))
  fit.lasso$beta    = coef(fit.lasso)[-1]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.ridge           = system.time(
  fit.ridge        <- cv.glmnet(x = X, y = y, alpha = 0, standardize = standardize))
  fit.ridge$beta    = coef(fit.ridge)[-1]
  t.enet = system.time(
  fit.enet         <- cv.glmnet(x = X, y = y, alpha = 0.9, standardize = standardize))
  fit.enet$beta     = coef(fit.enet)[-1]
  t.blasso          = system.time(
  fit.blasso       <- BGLR(y, ETA = list(list(X = X, model="BL", standardize = standardize)), verbose = FALSE))
  fit.blasso$beta   = fit.blasso$ETA[[1]]$b
  t.bayesB          = system.time(
  fit.bayesB       <- BGLR(y, ETA = list(list(X = X, model="BayesB", standardize = standardize)), verbose = FALSE))
  fit.bayesB$beta   = fit.blasso$ETA[[1]]$b * fit.bayesB$ETA[[1]]$d
  t.varbvs          = system.time(
  fit.varbvs       <- varbvs(X, Z = NULL, y, verbose = FALSE));
  fit.varbvs$beta   = rowSums(fit.varbvs$alpha * fit.varbvs$mu)
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds=10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pred23[i,] =  c("mrash"     = norm(y.test - predict(fit.mrash, X.test), '2'),
                 "susie"      = norm(y.test - predict(fit.susie, X.test), '2'),
                 "varbvs"     = norm(y.test - predict(fit.varbvs, X.test), '2'),
                 "L0Learn"    = norm(y.test - predict(fit.L0Learn, newx = X.test, lambda = lambda.min)@x, '2'),
                 "lasso"      = norm(y.test - predict(fit.lasso$glmnet.fit, newx = X.test,
                                                      s = fit.lasso$lambda.1se), '2'),
                 "ridge"      = norm(y.test - predict(fit.ridge$glmnet.fit, newx = X.test,
                                                      s = fit.ridge$lambda.1se), '2'),
                 "enet"       = norm(y.test - predict(fit.enet$glmnet.fit, newx = X.test,
                                                      s = fit.enet$lambda.1se), '2'),
                 "blasso"     = norm(y.test - X.test %*% fit.blasso$beta, '2'),
                 "bayesB"     = norm(y.test - X.test %*% fit.bayesB$beta, '2'))
  t33[i,] =     c("mrash"     = t.mrash[3],
                 "susie"      = t.susie[3],
                 "varbvs"     = t.varbvs[3],
                 "L0Learn"    = t.L0Learn[3],
                 "lasso"      = t.lasso[3],
                 "ridge"      = t.ridge[3],
                 "enet"       = t.enet[3],
                 "blasso"     = t.blasso[3],
                 "bayesB"     = t.bayesB[3])
  cat(pred33[i,],"\n")
  cat(t33[i,],"\n")
}
```

## Save results

We save results as follows. One may find .txt files in the following path.

```{r}
numlist = c(11,12,13,21,22,23,31,32,33)

for (nums in numlist) {
  df =   data.frame("fit" = rep(c("CAISA","SUSIE","VARBVS","L0Learn","LASSO",
                                  "RIDGE","E-NET","BLASSO","BayesB"), each = 20),
                    "pred" = c(get(paste("pred", nums, sep = ""))))
  write.table(df, paste(paste("../outputs/pred8", nums, sep = ""), ".txt", sep = ""), sep = ",")
  
  df =   data.frame("fit" = rep(c("CAISA","SUSIE","VARBVS","L0Learn","LASSO",
                                  "RIDGE","E-NET","BLASSO","BayesB"), each = 20),
                    "time" = c(get(paste("t", nums, sep = ""))))
  write.table(df, paste(paste("../outputs/time8", nums, sep = ""), ".txt", sep = ""), sep = ",")
}
```
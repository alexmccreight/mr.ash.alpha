---
title: "Experiment 1 (Update Order)"
author: "Youngseok Kim"
date: "6/23/2019"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

This .Rmd file is to study how the order of coordinate updates may affect the quality of the solution. To this end, we will consider 6 different update orders and 3 different design settings.

### Evaluation

How do we measure performance for different update orders? We assess and compare different update orders by investigating variational objective values (i.e. negative ELBO) upon convergence. This is a most natural evaluation criterion since all methods solve the same optizatiom problem. The smaller variational objective values achieved at stationary points, the better solutions corresponding update orders output.

Another possible evaluation metric is prediction error, but usually we strongly believe that a smaller variational objective value should yield a smaller prediction error.

### Default settings

We use n = 500, p = 2000 and s = 100 where n,p and s denote
the number of samples,
the number of coefficients
and
the number of nonzero coefficients.
But nonzero indices will be chosen randomly, and s will be approximately equal to 100 but not always be equal to 100 due to the randomness. See below codes for details.

We also use PVE = 0.5 for our default setting.

A default signal shape for nonzero coefficients is normal distribution. If we pre-specify PVE, then the signal shape is then automatically determined by sparse + normal. This will be called SparseNormal

Finally, the posterior mean of beta will be initialized at a vector of zeros. We will call this null initialization.

In what follows, we consider several different update orders and design matrices.

### Update order 

1. Random order (permutation of 1:p)
2. Fixed order (1:p)
3. ENET regularization path order
4. Absolute values of cross validated ENET solution
5. Absolute values of univariate regression coefficients
6. Any other information indicating significance of variables (boosting feature importance will be used)

### Design setting 

For design matrix, we will use three different design settings.

1. An independent Gaussian design, i.e. $X_{ij} \sim N(0,1)$ i.i.d. We will call this design setting IndepGauss.

2. An equally correlated gaussian design, i.e. $ X_j \sim N(0,\Sigma)$ where $\Sigma$ has unit diagonal entries and equal off-diagonal entries $\rho < 1$. We will call this design setting EquiCorrGauss.

3. A real genotype matrix from GTEx. We will call this design setting RealGenotype.

### Disclosure

This .Rmd file is to reproduce the result for a figure in the paper. Results for timings can be slightly different even in the same computing machine. Also, it can be nontrivially different if you use different computing machine. But it should not be very different. Anyway, the variational objective valud and the prediction error presented below must be the same.

### Load libraries, packages and codes

We load libraries, packages and codes for the simulation and for the plotting.

```{r loadpac}
library(Matrix); library(Rcpp); library(varbvs); library(ggplot2); library(cowplot); library(L0Learn)
library(glmnet); library(susieR); library(BGLR); library(varbvs2); library(xgboost)
```

### Filepath for real genotype matrices

We will use private Thyroid data sets retrieved from GTEx consortium (https://gtexportal.org/). The below files therefore should be downloaded by oneself.

```{r filepath}
filepath = c("../data/Thyroid.ENSG00000000971.RDS", "../data/Thyroid.ENSG00000004468.RDS",
             "../data/Thyroid.ENSG00000004777.RDS", "../data/Thyroid.ENSG00000007402.RDS",
             "../data/Thyroid.ENSG00000008441.RDS", "../data/Thyroid.ENSG00000008869.RDS",
             "../data/Thyroid.ENSG00000009954.RDS", "../data/Thyroid.ENSG00000010295.RDS",
             "../data/Thyroid.ENSG00000011638.RDS", "../data/Thyroid.ENSG00000016864.RDS",
             "../data/Thyroid.ENSG00000018280.RDS", "../data/Thyroid.ENSG00000019169.RDS",
             "../data/Thyroid.ENSG00000020922.RDS", "../data/Thyroid.ENSG00000044574.RDS",
             "../data/Thyroid.ENSG00000026950.RDS", "../data/Thyroid.ENSG00000028839.RDS",
             "../data/Thyroid.ENSG00000031003.RDS", "../data/Thyroid.ENSG00000031823.RDS",
             "../data/Thyroid.ENSG00000033030.RDS", "../data/Thyroid.ENSG00000036054.RDS")
```

### function for glmnet order

The following function is to compute glmnet path order using the default setting of the glmnet R package. The path is not exhaustive since nlambda = 100 is the default setting of glmnet package. Therefore, a couple of coefficients will appear in the glmnet path at the same time. In this case, we use a lexicographic order.

```{r lassoroder}
lasso_order = function(fit.glmnet) {
  # perform lasso regression and reorder regressors by "importance"
  beta_path = coef(fit.glmnet)[-1,]
  K = dim(beta_path)[2]
  path_order = c()
  for (k in 1:K) {
    crt_path = which(beta_path[,k] != 0)
    if (length(crt_path) != 0 & length(path_order) == 0) {
      path_order = c(path_order, crt_path)
    } else if(length(crt_path) != 0) {
      path_order = c(path_order, crt_path[-which(crt_path %in% path_order)] )
    }
  }
  path_order = unname(path_order)
  index_order = c(path_order, seq(1,dim(beta_path)[1])[-path_order])
  return (index_order)
}
```

## Define global variables

```{r simsetting}
numiter = 20
```

### IndepLowdimGauss + SparseNormal

In this setting, each entry of $X$ is i.i.d. standard normal and $X$ is low-dimensional. In this case, we expect the update order does not really affect performance of MR_ASH. This is because in this case the objective function may behave well on a set of sparse coefficients, so any updating orders may yield the same solution.

### IndepGauss + SparseNormal

In this setting, each entry of $X$ is i.i.d. standard normal, i.e. $X_{ij} \sim N(0,1)$.

```{r sim1}
varobj0 = matrix(0,20,6)
pred0   = matrix(0,20,7)
t0      = matrix(0,20,7)
cat(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order",
      "univar.order", "import.order"), "\n")
for (i in 1:numiter) {
  standardize       = FALSE
  
  X                <- matrix(rnorm(1000 * 2000), 1000, 2000)
  n                 = dim(X)[1]
  p                 = dim(X)[2]
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.05,0.95)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(sum(beta^2))
  y                <- X %*% beta + sigma * rnorm(n)
  X.test           <- matrix(rnorm(n*p), n, p)
  y.test           <- X.test %*% beta + sigma * rnorm(n)
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  #cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  # order based on regularization path of elastic net
  t.enet            = system.time(
  fit.enet         <- glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  path.order        = lasso_order(fit.enet) - 1
  
  # order based on absolute values of cross validated elastic net output
  t.enet2           = system.time(
  cv.enet          <- cv.glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  enet.order        = order(abs(coef(cv.enet)[-1]), decreasing = TRUE) - 1
  
  # order based on absolute values of univariate regression coefficients
  # since X is very regularly structured, we simply use t(X) %*% y
  # without considering standardization and intercept
  univar.order      = order(abs(t(X) %*% y)) - 1
  
  # order based on variable importance
  dtrain           <- xgb.DMatrix(X, label = y)
  param            <- list(booster = "gblinear",
                           objective = "reg:linear",
                           max_depth = 2,
                           eval_metric = 'rmse')
  # Perform xgboost cross-validation
  xgb_cv           <- xgb.cv(data=dtrain, params=param, nrounds=100, prediction=TRUE, maximize=FALSE,
                             nfold = 10, early_stopping_rounds = 30, verbose = 0, 
                             eta = 0.01)
  nrounds <- xgb_cv$best_iteration
  xgb              <- xgb.train(params = param, data = dtrain, nrounds = nrounds, verbose = 0)
  importance       <- xgb.importance(as.character(1:p), model = xgb)
  imp.order        <- as.numeric(importance$Feature) - 1
  
  
  
  t.mrash0          = system.time(
  fit.mrash0       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "random",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash1          = system.time(
  fit.mrash1       <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash2          = system.time(
  fit.mrash2       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash3          = system.time(
  fit.mrash3       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(enet.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash4          = system.time(
  fit.mrash4       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(univar.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash5          = system.time(
  fit.mrash5       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(imp.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  varobj0[i,] = c("random.order"    = fit.mrash0$varobj[fit.mrash0$iter],
                  "fixed.order"     = fit.mrash1$varobj[fit.mrash1$iter],
                  "path.order"      = fit.mrash2$varobj[fit.mrash2$iter],
                  "enet.order"      = fit.mrash3$varobj[fit.mrash3$iter],
                  "univar.order"    = fit.mrash4$varobj[fit.mrash4$iter],
                  "import.order"    = fit.mrash5$varobj[fit.mrash5$iter]
                  )
  
  pred0[i,]  = c("enet"            = norm(y.test - predict(cv.enet, X.test, s = cv.enet$lambda.1se), '2'),
                 "random.order"    = norm(y.test - predict(fit.mrash0, X.test), '2'),
                 "fixed.order"     = norm(y.test - predict(fit.mrash1, X.test), '2'),
                 "path.order"      = norm(y.test - predict(fit.mrash2, X.test), '2'),
                 "enet.order"      = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "univar.order"    = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "import.order"    = norm(y.test - predict(fit.mrash3, X.test), '2')
                 )
  
  t0[i,] = c("enet"            = t.enet2[3],
             "random.order"    = t.mrash0[3],
             "fixed.order"     = t.mrash1[3],
             "path.order"      = t.mrash2[3],
             "enet.order"      = t.mrash3[3],
             "univar.order"    = t.mrash4[3],
             "import.order"    = t.mrash5[3]
             )
  
  cat(varobj0[i,], "\n")
}
```

### EquiCorrGauss + SparseNormal

In this setting, each row $X_i$ follows $N(0,\Sigma)$ where $\Sigma$ has diagonal entries $1$ and off-diagonal entries $\rho$. We will use $\rho = 0.9$ for this case, since the update orders may yield very different solutions when columns of $X$ are highly correlated to one another.

```{r sim2}
varobj1 = matrix(0,20,6)
pred1   = matrix(0,20,7)
t1      = matrix(0,20,7)
cat(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order",
      "univar.order", "import.order"), "\n")
for (i in 1:numiter) {
  seed = (2010 + i)
  set.seed(seed)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  data$X           <- rnorm(dim(data$X)[1]) * sqrt(0.9) + data$X * sqrt(0.1)
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  
  standardize       = FALSE
  
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.05,0.95)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(sum(beta^2)) / sqrt(10)
  y.total           = data$X %*% beta + sigma * rnorm(n.total)
  
  y                 = y.total[train.index]
  y.test            = y.total[test.index]
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  # cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  # order based on regularization path of elastic net
  t.enet            = system.time(
  fit.enet         <- glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  path.order        = lasso_order(fit.enet) - 1
  
  # order based on absolute values of cross validated elastic net output
  t.enet2           = system.time(
  cv.enet          <- cv.glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  enet.order        = order(abs(coef(cv.enet)[-1]), decreasing = TRUE) - 1
  
  # order based on absolute values of univariate regression coefficients
  # since X is very regularly structured, we simply use t(X) %*% y
  # without considering standardization and intercept
  univar.order      = order(abs(t(X) %*% y)) - 1
  
  # order based on variable importance
  dtrain           <- xgb.DMatrix(X, label = y)
  param            <- list(booster = "gblinear",
                           objective = "reg:linear",
                           max_depth = 2,
                           eval_metric = 'rmse')
  # Perform xgboost cross-validation
  xgb_cv           <- xgb.cv(data=dtrain, params=param, nrounds=100, prediction=TRUE, maximize=FALSE,
                             nfold = 10, early_stopping_rounds = 30, verbose = 0, 
                             eta = 0.01)
  nrounds <- xgb_cv$best_iteration
  xgb              <- xgb.train(params = param, data = dtrain, nrounds = nrounds, verbose = 0)
  importance       <- xgb.importance(as.character(1:p), model = xgb)
  imp.order        <- as.numeric(importance$Feature) - 1
  
  
  
  t.mrash0          = system.time(
  fit.mrash0       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "random",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash1          = system.time(
  fit.mrash1       <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash2          = system.time(
  fit.mrash2       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash3          = system.time(
  fit.mrash3       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(enet.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash4          = system.time(
  fit.mrash4       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(univar.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash5          = system.time(
  fit.mrash5       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(imp.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  varobj1[i,] = c("random.order"    = fit.mrash0$varobj[fit.mrash0$iter],
                  "fixed.order"     = fit.mrash1$varobj[fit.mrash1$iter],
                  "path.order"      = fit.mrash2$varobj[fit.mrash2$iter],
                  "enet.order"      = fit.mrash3$varobj[fit.mrash3$iter],
                  "univar.order"    = fit.mrash4$varobj[fit.mrash4$iter],
                  "import.order"    = fit.mrash5$varobj[fit.mrash5$iter]
                  )
  
  pred1[i,]  = c("enet"            = norm(y.test - predict(cv.enet, X.test, s = cv.enet$lambda.1se), '2'),
                 "random.order"    = norm(y.test - predict(fit.mrash0, X.test), '2'),
                 "fixed.order"     = norm(y.test - predict(fit.mrash1, X.test), '2'),
                 "path.order"      = norm(y.test - predict(fit.mrash2, X.test), '2'),
                 "enet.order"      = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "univar.order"      = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "import.order"      = norm(y.test - predict(fit.mrash3, X.test), '2')
                 )
  
  t1[i,] = c("enet"            = t.enet2[3],
             "random.order"    = t.mrash0[3],
             "fixed.order"     = t.mrash1[3],
             "path.order"      = t.mrash2[3],
             "enet.order"      = t.mrash3[3],
             "univar.order"      = t.mrash4[3],
             "import.order"      = t.mrash5[3]
             )
  
  cat(varobj1[i,], "\n")
}
```

### EquiCorrGauss + SparseNormal

In this setting, $X$ is a real genotype matrix. Some columns are perfectly correlated or highly correlated (with correlation $> 0.99$) with other columns. Usually this local correlation structure is referred to the LD structure.

```{r sim3}
varobj2 = matrix(0,20,6)
pred2   = matrix(0,20,7)
t2      = matrix(0,20,7)
cat(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order",
      "univar.order", "import.order"), "\n")
for (i in 1:numiter) {
  seed = (2010 + i)
  set.seed(seed)
  data              = readRDS(filepath[i]);
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  
  standardize       = FALSE
  
  beta              = double(p)
  nzind             = which(sample(2, p, replace = TRUE, prob = c(0.01,0.99)) == 1)
  beta[nzind]       = rnorm(length(nzind)) * 2
  sigma             = sqrt(sum(beta^2)) / 10
  eps               = sigma * rnorm(n.total)
  y.total           = data$X %*% beta + eps
  
  y                 = y.total[train.index]
  y.test            = y.total[test.index]
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  
  #cat("pve =", var(X %*% beta) / (var(X %*% beta) + var(eps)),"\n")
  
  # order based on regularization path of elastic net
  t.enet            = system.time(
  fit.enet         <- glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  path.order        = lasso_order(fit.enet) - 1
  
  # order based on absolute values of cross validated elastic net output
  t.enet2           = system.time(
  cv.enet          <- cv.glmnet(x = X, y = y, standardize = standardize, alpha = .9))
  enet.order        = order(abs(coef(cv.enet)[-1]), decreasing = TRUE) - 1
  
  # order based on absolute values of univariate regression coefficients
  # since X is very regularly structured, we simply use t(X) %*% y
  # without considering standardization and intercept
  univar.order      = order(abs(t(X) %*% y)) - 1
  
  # order based on variable importance
  dtrain           <- xgb.DMatrix(X, label = y)
  param            <- list(booster = "gblinear",
                           objective = "reg:linear",
                           max_depth = 2,
                           eval_metric = 'rmse')
  # Perform xgboost cross-validation
  xgb_cv           <- xgb.cv(data=dtrain, params=param, nrounds=100, prediction=TRUE, maximize=FALSE,
                             nfold = 10, early_stopping_rounds = 30, verbose = 0, 
                             eta = 0.01)
  nrounds <- xgb_cv$best_iteration
  xgb              <- xgb.train(params = param, data = dtrain, nrounds = nrounds, verbose = 0)
  importance       <- xgb.importance(as.character(1:p), model = xgb)
  imp.order        <- as.numeric(importance$Feature) - 1
  
  
  
  t.mrash0          = system.time(
  fit.mrash0       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "random",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash1          = system.time(
  fit.mrash1       <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash2          = system.time(
  fit.mrash2       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(path.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash3          = system.time(
  fit.mrash3       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(enet.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash4          = system.time(
  fit.mrash4       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(univar.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  t.mrash5          = system.time(
  fit.mrash5       <- mr_ash_order(X = X, y = y, sa2 = sa2, order.method = "given",
                                   o = rep(imp.order, 2000),
                                   stepsize = 1, max.iter = 2000,
                                   standardize = standardize,
                                   tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  varobj2[i,] = c("random.order"    = fit.mrash0$varobj[fit.mrash0$iter],
                  "fixed.order"     = fit.mrash1$varobj[fit.mrash1$iter],
                  "path.order"      = fit.mrash2$varobj[fit.mrash2$iter],
                  "enet.order"      = fit.mrash3$varobj[fit.mrash3$iter],
                  "univar.order"    = fit.mrash4$varobj[fit.mrash4$iter],
                  "import.order"    = fit.mrash5$varobj[fit.mrash5$iter]
                  )
  
  pred2[i,]  = c("enet"            = norm(y.test - predict(cv.enet, X.test, s = cv.enet$lambda.1se), '2'),
                 "random.order"    = norm(y.test - predict(fit.mrash0, X.test), '2'),
                 "fixed.order"     = norm(y.test - predict(fit.mrash1, X.test), '2'),
                 "path.order"      = norm(y.test - predict(fit.mrash2, X.test), '2'),
                 "enet.order"      = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "univar.order"      = norm(y.test - predict(fit.mrash3, X.test), '2'),
                 "import.order"      = norm(y.test - predict(fit.mrash3, X.test), '2')
                 )
  
  t2[i,] = c("enet"            = t.enet2[3],
             "random.order"    = t.mrash0[3],
             "fixed.order"     = t.mrash1[3],
             "path.order"      = t.mrash2[3],
             "enet.order"      = t.mrash3[3],
             "univar.order"      = t.mrash4[3],
             "import.order"      = t.mrash5[3]
             )
  
  cat(varobj2[i,], "\n")
}
```

## Results

```{r}
## function for boxplot
my.box <- function (dat, x, y,
                    values = c(1,2,0,3,4,5)) {
  return(ggplot(dat,aes_string(x = x, y = y, fill = "fit")) +
           geom_jitter(aes(color = fit, shape = fit), width = .1) +
           scale_shape_manual(values = values) +
           geom_boxplot(alpha = 0.1, aes(color = fit), outlier.alpha = 0) +
           scale_alpha_manual(values = 0.1) +
           scale_fill_discrete(guide = "none") +
           labs(x           = "") +
           theme_cowplot(font_size = 18))
}

gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}
```

```{r}
varobj = rbind(colMeans(varobj0), colMeans(varobj1), colMeans(varobj2))
colnames(varobj) = c("random.order", "fixed.order", "enet.path.order", "enet.mag.order",
                  "univar.order", "import.order")
rownames(varobj) = c("IndepGauss", "EquiCorrGauss", "RealGenotype")

cat("variational objective values at solutions\n\n")
varobj
```

```{r}
t = rbind(colMeans(t0), colMeans(t1), colMeans(t2))
colnames(t) = c("elastic.net", "random.order", "fixed.order", "enet.path.order", "enet.mag.order",
                "univar.order", "import.order")
rownames(t) = c("IndepGauss", "EquiCorrGauss", "RealGenotype")

cat("computation time\n\n")
t
```

```{r}
```

```{r}
varobj0 = varobj0 - varobj0[,1]
df1 = data.frame(varobj = c(varobj0), fit = rep(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order", "univar.order", "import.order"), each = 20))
my.box(df1, "fit", "varobj", values = c(1,2,0,3,4,5)) +
    geom_abline(intercept = 0, slope = 0, color = gg_color_hue(6)[4], alpha = 0.8, linetype = 2, size = 0.2) +
  labs(title = "IndepGauss + SparseNormal",
       y     = "") + 
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none")
```

```{r}
varobj1 = varobj1 - varobj1[,1]
df1 = data.frame(varobj = c(varobj1), fit = rep(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order", "univar.order", "import.order"), each = 20))
my.box(df1, "fit", "varobj", values = c(1,2,0,3,4,5)) +
    geom_abline(intercept = 0, slope = 0, color = gg_color_hue(6)[4], alpha = 0.8, linetype = 2, size = 0.2) +
  labs(title = "EquiCorrGauss + SparseNormal",
       y     = "") + 
  scale_y_continuous(breaks = c(0,1,2)) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none")
```

```{r}
varobj2 = varobj2 - varobj2[,1]
df1 = data.frame(varobj = c(varobj2), fit = rep(c("random.order", "fixed.order", "enet.path.order", "enet.mag.order", "univar.order", "import.order"), each = 20))
my.box(df1, "fit", "varobj", values = c(1,2,0,3,4,5)) +
    geom_abline(intercept = 0, slope = 0, color = gg_color_hue(6)[4], alpha = 0.8, linetype = 2, size = 0.2) +
  labs(title = "RealGenotype + SparseNormal",
       y     = "") + 
  scale_y_continuous(breaks = c(0,1,2)) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none")
```






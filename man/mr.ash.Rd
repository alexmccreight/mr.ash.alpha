% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mr.ash.R, R/mr.ash.dev.R
\name{mr.ash}
\alias{mr.ash}
\alias{mr.ash.dev}
\title{Multiple Regression with Adaptive Shrinkage}
\usage{
mr.ash(
  X,
  y,
  Z = NULL,
  sa2 = NULL,
  method = c("caisa", "sigma", "sigma_scaled", "sigma_indep"),
  max.iter = 1000,
  min.iter = 1,
  beta.init = NULL,
  update.pi = TRUE,
  pi = NULL,
  update.sigma2 = TRUE,
  sigma2 = NULL,
  update.order = NULL,
  standardize = FALSE,
  intercept = TRUE,
  tol = set_default_tolerance()
)

mr.ash.dev(
  X,
  y,
  Z = NULL,
  sa2 = NULL,
  method = c("caisa", "accelerate", "block", "sigma", "sigma_scaled", "sigma_indep"),
  max.iter = 1000,
  min.iter = 1,
  beta.init = NULL,
  update.pi = TRUE,
  pi = NULL,
  update.sigma2 = TRUE,
  sigma2 = NULL,
  update.order = NULL,
  standardize = FALSE,
  intercept = TRUE,
  tol = set_default_tolerance()
)
}
\arguments{
\item{X}{The input matrix, of dimension (n,p); each column is a
single predictor; and each row is an observation vector. Here, n is
the number of samples and p is the number of predictors. Currently,
sparse matrix formats are not supported.}

\item{y}{The observed quantitative responses, a vector of length p.}

\item{Z}{The covariate matrix, of dimension (n,k), where k is the
number of covariates.  The input matrix Z can be modified according
to "intercept" argument. If \code{Z = NULL} and \code{intercept =
TRUE}, then the actual \code{Z} will be the matrix having entries 1
of dimension (n,1). If \code{Z = NULL} and \code{intercept =
FALSE}, no intercept or covariates are inclued the model. If
\code{Z} is not \code{NULL} and \code{intercept = TRUE}, then the
intercept is added as a covariate to \code{Z}.}

\item{sa2}{The vector of mixture component variances. The first
variance \code{sa2[1] must be set to zero. When \code{sa2 = NULL},
the default setting is used, \code{sa2[k] = (2^(0.05*(k-1)) -
1)^2}, for \code{k = 1:20}. For the default setting, \code{sa2[1] =
0}, and \code{sa2[20]} is roughly 1.}}

\item{method}{In the manuscript (see \sQuote{References}), only
\code{method = "caisa"} is used ("Cooridinate Ascent Iterative
Shinkage Algorithm"). Other method arguments will work, and produce
similar outcomes unless the regression setting is extreme. [(For
dev 1) The \code{method} arguments caisa, sigma, sigma_scaled,
sigma_indep use different updates for \eqn{sigma^2}, based on
different parametrizations on the variational posterior \eqn{q} and
\eqn{g}. More precisely, the update for \eqn{\sigma^2} depends on
whether we use sigma-dependent parametrization for \eqn{q} and/or
\eqn{g}. See reference for details. (For dev 2) Furthermore, we
also have different updates for \eqn{g}, but is not implemented in
this function \code{mr.ash}. See \code{mr.ash.dev} if you are
interested.]}

\item{max.iter}{The maximum number of "outer loop" iterations allowed.}

\item{min.iter}{The minimum number of "inner loop" iterations allowed.}

\item{beta.init}{The initial estimate of the (approximate)
posterior mean regression coefficients. This should be \code{NULL},
or a vector of length p. When \code{beta.init = NULL}, the
posterior mean coefficients are all initially zero.}

\item{update.pi}{If \code{update.pi = TRUE}, the mixture
proportions in the mixture-of-normals prior are estimated from the
data. In the manuscript, \code{update.pi = TRUE}.}

\item{pi}{The initial estimate of the mixture proportions
\eqn{\pi_1,...,\pi_K}. If \code{pi = NULL}, the default value
\code{pi[k] = 1/K} for k = 1,...,K will be used.}

\item{update.sigma2}{If \code{update.sigma2 = TRUE}, the residual
variance \eqn{sigma^2} is estimated from the data.  In the manuscript,
\code{update.sigma = TRUE}.}

\item{sigma2}{The initial estimate of the residual variance,
\eqn{\sigma^2}. If \code{sigma2 = NULL}, the residual variance is
initialized to the empirical variance of the residuals based on the
initial estimates of the regression coefficients, \code{beta.init},
after removing linear effects of the intercept and any covariances.}

\item{update.order}{Describe input argument "update.order" here.}

\item{standardize}{The logical flag for standardization of the
columns of X variable, prior to the model fitting. The coefficients
are always returned on the original scale.}

\item{intercept}{The logical flag for including intercept (\code{intercept = TRUE})
to the model or not (\code{intercept = FALSE}).}

\item{tol}{The default tolerance is \code{epstol = 1e-12} and \code{convtol = 1e-8}.
See the documentation for \code{set_default_tolerance}. \code{epstol} stands for the
safeguard tolerance for mixture proportions (e.g. when \code{pi[1] * log(pi[1])} is
computed), and \code{convtol} stands for convergence tolerance.}
}
\value{
A list object with the following elements:

\item{intercept}{An intercept.}

\item{beta}{A vector of estimated regression coefficients (variational posterior means), 
after fixed effects (e.g. intercept) from covariates are subtracted out.}

\item{sigma2}{A scalar value of estimated noise variance (approximate maximum likelihood).}

\item{pi}{A vector of estimated mixture proportions of length K, where \code{K = length(sa2)}.}

\item{iter}{The number of total outer loop iterations implemented in the coordinate ascent algorithm.}

\item{varobj}{A sequence of variational objective values (which equals the negative evidence lower bound).
\code{length(varobj)} should be equal to \code{iter}.}

\item{data}{A preprocessed data used as the actual input for the algorithm. When \code{Z = NULL}
and \code{intercept = TRUE}, then the columns of X and y will be centered, and returned.
In general, Z will be regressed out, or equivalently, X and y will be projected into the space
orthogonal to Z, and then will be returned.}

\item{update.order}{An update order used for the outer loop iterations.}
}
\description{
Model fitting algorithms for Multiple Regression with
Adaptive Shrinkage ("Mr.ASH"), a variational empirical Bayes (VEB)
method for multiple linear regression. The fitting algorithms
maximize the approximate marginal likelihood ("evidence lower
bound", or "ELBO") via co-ordinate ascent updates.
}
\details{
The VEB approach is based on the multiple linear
regression model: \deqn{y|X,\beta,\sigma^2 ~ N(X\beta, \sigma^2
I_n), \beta | \pi, \sigma^2 ~ \sum_{k=1}^K N(0,\sigma^2\sigma_k^2)}
Here \eqn{\sigma_k^2} is the k-th mixture component variance
\code{sa2[k]} (note that \eqn{\sigma^2}) is dropped.), and \eqn{K}
is the number of mixture components \code{length(sa2)}.  The other
parameters are described in the \sQuote{Arguments}.

The VEB approach solves the following optimization problem:
\deqn{F(q,g,\sigma^2) = E_q \log p(y|X,\beta,\sigma^2) -
\sum_{j=1}^p D_{KL}(q_j || g)} The algorithm updates the
variational factors \eqn{q_1,...,q_p}, \eqn{g} and \eqn{\sigma^2}
one at a time while fixing the others, in each outer loop
iteration.

The algorithm does not store the full variational posterior \eqn{q
= (q_1,...,q_p)}, but only stores the variational posterior mean
\code{beta} for each regression coefficients.  In order to recover
the full posterior, see the documentation for
\code{get.full.posterior} function.

See \sQuote{References} for more details about the VEB approach.
}
\examples{
### generate synthetic data
set.seed(1)
n           = 200
p           = 300
X           = matrix(rnorm(n*p),n,p)
beta        = double(p)
beta[1:10]  = 1:10
y           = X \%*\% beta + rnorm(n)

### fit Mr.ASH
fit.mr.ash  = mr.ash(X,y, method = "caisa")

### prediction routine
Xnew        = matrix(rnorm(n*p),n,p)
ynew        = Xnew \%*\% beta + rnorm(n)
ypred       = predict(fit.mr.ash, Xnew)

### test error
rmse        = norm(ynew - ypred, '2') / sqrt(n)

### coefficients
betahat     = predict(fit.mr.ash, type = "coefficients")
# this equals c(fit.mr.ash$intercept, fit.mr.ash$beta)

}
\references{
Y. Kim, W. Wang, P. Carbonetto, M. Stephens (2020). Fast and
flexible empirical Bayes approach to prediction in multiple
regression.
}
\seealso{
The documentation for \code{get.full.posterior} function
for recovering the full posterior from the \code{mr.ash} fit. Also,
see the documentation for \code{mr.ash.dev} if you are interested
in additional functionality that are not used in the paper (see
\sQuote{References}).

\code{\link{get.full.posterior}}
}

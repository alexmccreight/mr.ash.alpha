---
title: "Experiment 2 (Nonconvex)"
author: "Youngseok Kim"
date: "10/01/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This .Rmd file is to reproduce the result for a figure in the paper.

### Goal

In what follows, we compare mr.ash with 

### Load libraries, packages and codes

We load libraries, packages and codes for the simulation and for the plotting.

```{r}
library(ggplot2); library(cowplot); library(glmnet); library(ncvreg); library(L0Learn); library(varbvs2)
```

### Simulation setting

#### Design matrix

We will use is an independent low dimensional Gaussian ensemble design. For abbreviation, we will call this design matrix "IndepLowdimGauss". A matrix size $n = 1010$ and $p = 1000$ will be fixed. The design matrix will be generated as follows.

```{r}
standardize = FALSE
#X                <- matrix(rnorm(500*1000), 500, 1000)
#X                <- rnorm(dim(X)[1]) * sqrt(0.5) + X * sqrt(0.5)
```

## Simulation

### Signal Shape 1 : SparseNormal

#### Signal = SparseNormal9

```{r sparsenormal5, eval = FALSE}
pred11 = matrix(0,20,5)
t11    = matrix(0,20,5)
null11 = double(20)
best11 = double(20)
sigma11 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  beta[sample(p,5)] = rnorm(5) * 2
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null11[i]         = norm(y.test, '2')
  best11[i]         = norm(err.test, '2')
  sigma11[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred11[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t11[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  mcp.lambda            = fit.mcp$lambda.min
  mcp.gamma             = 3.7
  scad.lambda           = fit.scad$lambda.min
  scad.gamma            = 3
  lasso.lambda          = fit.lasso$lambda.1se
  L0Learn.lambda        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pi                    = c(fit.mrash$pi)
  sigma2                = fit.mrash$sigma2
  
  cat(pred11[i,],"\n")
  cat(t11[i,],"\n")
}
```

```{r sparsenormal10, eval = FALSE}
pred12 = matrix(0,20,5)
t12    = matrix(0,20,5)
null12 = double(20)
best12 = double(20)
sigma12 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  beta[sample(p,10)] = rnorm(10) * 2
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null12[i]         = norm(y.test, '2')
  best12[i]         = norm(err.test, '2')
  sigma12[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred12[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t12[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred12[i,],"\n")
  cat(t12[i,],"\n")
}
```

```{r sparsenormal20, eval = FALSE}
pred13 = matrix(0,20,5)
t13    = matrix(0,20,5)
null13 = double(20)
best13 = double(20)
sigma13 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  beta[sample(p,20)] = rnorm(20) * 2
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null13[i]         = norm(y.test, '2')
  best13[i]         = norm(err.test, '2')
  sigma13[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred13[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t13[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred13[i,],"\n")
  cat(t13[i,],"\n")
}
```

```{r sparsenormal40, eval = FALSE}
pred14 = matrix(0,20,5)
t14    = matrix(0,20,5)
null14 = double(20)
best14 = double(20)
sigma14 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  beta[sample(p,40)] = rnorm(40) * 2
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null14[i]         = norm(y.test, '2')
  best14[i]         = norm(err.test, '2')
  sigma14[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred14[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t14[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred14[i,],"\n")
  cat(t14[i,],"\n")
}
```

#### Signal Shape = ThreePointMass

```{r threepointmass5, eval = FALSE}
pred21 = matrix(0,20,5)
t21    = matrix(0,20,5)
null21 = double(20)
best21 = double(20)
sigma21 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,5)
  beta[ind[1:4]]    = 1
  beta[ind[5]]      = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null21[i]         = norm(y.test, '2')
  best21[i]         = norm(err.test, '2')
  sigma21[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred21[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t21[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  mcp.lambda            = fit.mcp$lambda.min
  mcp.gamma             = 3.7
  scad.lambda           = fit.scad$lambda.min
  scad.gamma            = 3
  lasso.lambda          = fit.lasso$lambda.1se
  L0Learn.lambda        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pi                    = c(fit.mrash$pi)
  sigma2                = fit.mrash$sigma2
  
  cat(pred21[i,],"\n")
  cat(t21[i,],"\n")
}
```

```{r threepointmass10, eval = FALSE}
pred22 = matrix(0,20,5)
t22    = matrix(0,20,5)
null22 = double(20)
best22 = double(20)
sigma22 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,10)
  beta[ind[1:8]]   = 1
  beta[ind[9:10]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null22[i]         = norm(y.test, '2')
  best22[i]         = norm(err.test, '2')
  sigma22[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred22[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t22[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred22[i,],"\n")
  cat(t22[i,],"\n")
}
```

```{r threepointmass20, eval = FALSE}
pred23 = matrix(0,20,5)
t23    = matrix(0,20,5)
null23 = double(20)
best23 = double(20)
sigma23 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,20)
  beta[ind[1:16]]   = 1
  beta[ind[17:20]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null23[i]         = norm(y.test, '2')
  best23[i]         = norm(err.test, '2')
  sigma23[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred23[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t23[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred23[i,],"\n")
  cat(t23[i,],"\n")
}
```

```{r threepointmass40, eval = FALSE}
pred24 = matrix(0,20,5)
t24    = matrix(0,20,5)
null24 = double(20)
best24 = double(20)
sigma24 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,40)
  beta[ind[1:32]]   = 1
  beta[ind[33:40]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null24[i]         = norm(y.test, '2')
  best24[i]         = norm(err.test, '2')
  sigma24[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred24[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t24[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred24[i,],"\n")
  cat(t24[i,],"\n")
}
```

#### Signal Shape = Bimodal

```{r threepointmass5, eval = FALSE}
pred31 = matrix(0,20,5)
t31    = matrix(0,20,5)
null31 = double(20)
best31 = double(20)
sigma31 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  beta[1:5]         = rnorm(5,1,1)
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null31[i]         = norm(y.test, '2')
  best31[i]         = norm(err.test, '2')
  sigma31[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred31[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t31[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  mcp.lambda            = fit.mcp$lambda.min
  mcp.gamma             = 3.7
  scad.lambda           = fit.scad$lambda.min
  scad.gamma            = 3
  lasso.lambda          = fit.lasso$lambda.1se
  L0Learn.lambda        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  pi                    = c(fit.mrash$pi)
  sigma2                = fit.mrash$sigma2
  
  cat(pred31[i,],"\n")
  cat(t31[i,],"\n")
}
```

```{r threepointmass10, eval = FALSE}
pred22 = matrix(0,20,5)
t22    = matrix(0,20,5)
null22 = double(20)
best22 = double(20)
sigma22 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,10)
  beta[ind[1:8]]   = 1
  beta[ind[9:10]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null22[i]         = norm(y.test, '2')
  best22[i]         = norm(err.test, '2')
  sigma22[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred22[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t22[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred22[i,],"\n")
  cat(t22[i,],"\n")
}
```

```{r threepointmass20, eval = FALSE}
pred23 = matrix(0,20,5)
t23    = matrix(0,20,5)
null23 = double(20)
best23 = double(20)
sigma23 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,20)
  beta[ind[1:16]]   = 1
  beta[ind[17:20]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null23[i]         = norm(y.test, '2')
  best23[i]         = norm(err.test, '2')
  sigma23[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred23[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t23[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred23[i,],"\n")
  cat(t23[i,],"\n")
}
```

```{r threepointmass40, eval = FALSE}
pred24 = matrix(0,20,5)
t24    = matrix(0,20,5)
null24 = double(20)
best24 = double(20)
sigma24 = double(20)

for (i in 1:20) {
  set.seed(2010 + i)
  data              = list(X = matrix(rnorm(1000*2000), 1000, 2000))
  n.total           = dim(data$X)[1];
  p                 = dim(data$X)[2]
  train.index       = sample(n.total, floor(n.total * 0.5))
  test.index        = (1:n.total)[-train.index]
  X                 = data$X[train.index,]
  X.test            = data$X[test.index,]
  beta              = double(p)
  ind               = sample(p,40)
  beta[ind[1:32]]   = 1
  beta[ind[33:40]]  = 10
  sigma             = sqrt(sum(beta^2) / 99)
  y                <- X %*% beta + sigma * rnorm(500)
  err.test          = sigma * rnorm(500)
  y.test           <- X.test %*% beta + err.test
  sa2               = (sqrt(1.5)^(0:19) - 1)^2
  null24[i]         = norm(y.test, '2')
  best24[i]         = norm(err.test, '2')
  sigma24[i]        = sigma
  
  cat("pve =", mean((X %*% beta)^2) / mean(y^2),"\n")
  
  t.scad            = system.time(
  fit.scad         <- cv.ncvreg(X, y, penalty = "SCAD", nfolds = 5))
    
  t.mcp             = system.time(
  fit.mcp          <- cv.ncvreg(X, y, penalty = "MCP", nfolds = 5))
    
  t.lasso           = system.time(
  fit.lasso        <- cv.glmnet(x = X, y = y, alpha = 1, standardize = standardize))
    
  t.L0Learn         = system.time(
  fit.L0Learn      <- L0Learn.cvfit(X, y, nFolds = 10))
  lambda.min        = fit.L0Learn$fit$lambda[[1]][which.min(fit.L0Learn$cvMeans[[1]])]
  
  t.mrash           = system.time(
  fit.mrash        <- mr_ash(X = X, y = y, sa2 = sa2,
                             stepsize = 1, max.iter = 2000,
                             standardize = standardize,
                             tol = list(epstol = 1e-12, convtol = 1e-8)))
  
  pred24[i,] =  c("mrash"      = norm(y.test - predict(fit.mrash, X.test), '2'),
                  "scad"       = norm(y.test - predict(fit.scad, X.test), '2'),
                  "mcp"        = norm(y.test - predict(fit.mcp, X.test), '2'),
                  "lasso"      = norm(y.test - predict(fit.lasso, X.test), '2'),
                  "L0Learn"    = norm(y.test - predict(fit.L0Learn, X.test, lambda = lambda.min)@x, '2'))
  t24[i,] =     c("mrash"      = t.mrash[3],
                  "scad"       = t.scad[3],
                  "mcp"        = t.mcp[3],
                  "lasso"      = t.lasso[3],
                  "t.L0Learn"  = t.L0Learn[3])
  
  cat(pred24[i,],"\n")
  cat(t24[i,],"\n")
}
```

```{r datasummary, eval = FALSE}
numlist = c(11,12,13,14,21,22,23,24)
dat = list()
for (i in 1:length(numlist)) {
  num = numlist[i]
  
  dat[[i]] = data.frame(pred = c(get(paste("pred", num, sep = ""))), time = c(get(paste("t", num, sep = ""))),
                        fit = rep(c("MR.ASH","SCAD","MCP","L0Learn","LASSO"), each = 20))
  dat[[i]]$rmse = dat[[i]]$pred / sqrt(500)
  dat[[i]]$best = get(paste("best", num, sep = ""))
  dat[[i]]$null = get(paste("null", num, sep = ""))
  dat[[i]]$rrmse = (dat[[i]]$pred - dat[[i]]$best) / (dat[[i]]$null - dat[[i]]$best)
  dat[[i]]$rrmse2 = pmin(pmax(dat[[i]]$rrmse, 0),1)
  dat[[i]]$sigma = get(paste("sigma", num, sep = ""))
  dat[[i]]$p = 2000
}
saveRDS(dat, "../paperresults/experiment2.rds")
```

```{r readresults, message = FALSE}
dat = readRDS("../paperresults/experiment2.rds")
for (i in 1:8) {
  dat[[i]]$nrmse = dat[[i]]$rmse / dat[[i]]$sigma
}
```

```{r}
sdat = list()
for (i in 1:4) {
  sdat[[i]] = data.frame(mean = colMeans(matrix(dat[[i]]$nrmse, nrow = 20)),
                         fit = c("MR.ASH","SCAD","MCP","L0Learn","LASSO"),
                         nz = 5 * 2^(i-1),
                         ymin = apply(matrix(dat[[i]]$nrmse, nrow = 20), 2, function(x) quantile(x, probs = 0.25)),
                         ymax = apply(matrix(dat[[i]]$nrmse, nrow = 20), 2, function(x) quantile(x, probs = 0.75)))
}

df = rbind(sdat[[1]], sdat[[2]], sdat[[3]], sdat[[4]])
ggplot(df) + geom_line(aes(x = nz, y = mean, color = fit)) + theme_cowplot(font_size = 14) +
  #geom_errorbar(aes(x = nz, ymin = ymin, ymax = ymax, color = fit), width = .02, position=position_dodge(.01)) +
  scale_x_continuous(trans = "log10", breaks = c(5,10,20,40)) +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  labs(x = "number of nonzero coefficients (s)",
       y = "prediction error (rmse/sigma)",
       title = "SparseNormal")
```

```{r}
sdat = list()
for (i in 1:4) {
  sdat[[i]] = data.frame(mean = colMeans(matrix(dat[[i+4]]$nrmse, nrow = 20)),
                         fit = c("MR.ASH","SCAD","MCP","L0Learn","LASSO"),
                         nz = 5 * 2^(i-1),
                         ymin = apply(matrix(dat[[i+4]]$nrmse, nrow = 20), 2, function(x) quantile(x, probs = 0.25)),
                         ymax = apply(matrix(dat[[i+4]]$nrmse, nrow = 20), 2, function(x) quantile(x, probs = 0.75)))
}

df = rbind(sdat[[1]], sdat[[2]], sdat[[3]], sdat[[4]])
ggplot(df) + geom_line(aes(x = nz, y = mean, color = fit)) + theme_cowplot(font_size = 14) +
  #geom_errorbar(aes(x = nz, ymin = ymin, ymax = ymax, color = fit), width = .02, position=position_dodge(.05)) + 
  scale_x_continuous(trans = "log10", breaks = c(5,10,20,40)) +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  labs(x = "number of nonzero coefficients (s)",
       y = "prediction error (rmse/sigma)",
       title = "ThreePointMass")
```
